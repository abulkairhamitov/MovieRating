{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T14:07:27.742692Z",
     "start_time": "2023-07-23T14:07:22.890426Z"
    },
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchtext\n",
    "\n",
    "#df=pd.DataFrame(columns = ['text', 'rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T11:27:23.041609Z",
     "start_time": "2023-07-22T11:27:23.032080Z"
    }
   },
   "outputs": [],
   "source": [
    "# for directory in ['./train/pos/', './train/neg/']:\n",
    "#     for dirname, _, filenames in os.walk(directory):\n",
    "#         for filename in filenames:\n",
    "#             file = open(dirname + '/' + filename, encoding=\"utf8\")\n",
    "#             text = file.read()\n",
    "#             s = file.name.replace(directory, '').replace('.txt', '')\n",
    "#             ID = s[0:s.find('_')]\n",
    "#             rating = s[s.find('_')+1:]\n",
    "#             newRow = {'text': text, 'rating': rating}\n",
    "#             df = pd.concat([df, pd.DataFrame([newRow])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T11:27:23.706787Z",
     "start_time": "2023-07-22T11:27:23.697228Z"
    }
   },
   "outputs": [],
   "source": [
    "# for directory in ['./test/pos/', './test/neg/']:\n",
    "#     for dirname, _, filenames in os.walk(directory):\n",
    "#         for filename in filenames:\n",
    "#             file = open(dirname + '/' + filename, encoding=\"utf8\")\n",
    "#             text = file.read()\n",
    "#             s = file.name.replace(directory, '').replace('.txt', '')\n",
    "#             ID = s[0:s.find('_')]\n",
    "#             rating = s[s.find('_')+1:]\n",
    "#             newRow = {'text': text, 'rating': rating}\n",
    "#             df = pd.concat([df, pd.DataFrame([newRow])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T11:27:25.704619Z",
     "start_time": "2023-07-22T11:27:25.695058Z"
    }
   },
   "outputs": [],
   "source": [
    "# df.to_csv ('train_data.csv', index= False )\n",
    "# df.to_csv ('test_data.csv', index= False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T11:27:26.005985Z",
     "start_time": "2023-07-22T11:27:26.000792Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_test = pd.read_csv('test_data.csv')\n",
    "# df_train = pd.read_csv('train_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepocessing of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T13:12:43.544078Z",
     "start_time": "2023-07-22T13:12:43.539055Z"
    }
   },
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "from collections import Counter\n",
    "import re\n",
    "from torchtext.data import get_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T13:11:43.538347Z",
     "start_time": "2023-07-22T13:11:43.534327Z"
    }
   },
   "outputs": [],
   "source": [
    "train_path = 'train_data.csv'\n",
    "test_path = 'test_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T13:11:44.430207Z",
     "start_time": "2023-07-22T13:11:44.418148Z"
    }
   },
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, path):\n",
    "        self.df = pd.read_csv(path)\n",
    "        self.df = self.df.sample(frac=1).reset_index(drop=True)\n",
    "    def encoder(self, word):\n",
    "        if word in word2idx.keys():\n",
    "            return word2idx[word]\n",
    "        return word2idx['lurum']\n",
    "    def array_word2vec(self, arr):\n",
    "        result = []\n",
    "        for elem in arr:\n",
    "            if elem not in word2vec:\n",
    "                result.append(word2vec['unc'])\n",
    "            else:\n",
    "                result.append(word2vec[elem])\n",
    "        return result\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, index):\n",
    "        review = re.sub(r'\\W', ' ', str(self.df.iloc[index]['text']))\n",
    "        review = review.lower()\n",
    "        review = re.sub(r'^br$', ' ', review)\n",
    "        review = re.sub(r'\\s+br\\s+',' ',review)\n",
    "        review = re.sub(r'\\s+[a-z]\\s+', ' ',review)\n",
    "        review = re.sub(r'^b\\s+', '', review)\n",
    "        review = re.sub(r'\\s+', ' ', review)\n",
    "        \n",
    "        rating = self.df.iloc[index]['rating']\n",
    "        rating = rating - 1 if rating <= 4 else rating - 3\n",
    "        return review, rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T13:12:06.214390Z",
     "start_time": "2023-07-22T13:11:47.527310Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchtext.vocab import GloVe\n",
    "\n",
    "global_vectors = GloVe(name='840B', dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T13:13:36.517506Z",
     "start_time": "2023-07-22T13:12:51.012809Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "\n",
    "max_words = 500\n",
    "embed_len = 300\n",
    "\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "from torchtext.data import get_tokenizer\n",
    "\n",
    "def vectorize_batch(batch):\n",
    "    X, Y = list(zip(*batch))\n",
    "    X = [tokenizer(x) for x in X]\n",
    "    X = [tokens+[\"\"] * (max_words-len(tokens))  if len(tokens) < max_words else tokens[:max_words] for tokens in X]\n",
    "    X_tensor = torch.zeros(len(batch), max_words, embed_len)\n",
    "    for i, tokens in enumerate(X):\n",
    "        X_tensor[i] = global_vectors.get_vecs_by_tokens(tokens)\n",
    "    return X_tensor.mean(dim=1), torch.tensor(Y)\n",
    "\n",
    "train_dataset, test_dataset  = Dataset(train_path), Dataset(test_path)\n",
    "train_dataset, test_dataset = to_map_style_dataset(train_dataset), to_map_style_dataset(test_dataset)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1024, collate_fn=vectorize_batch)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=1024, collate_fn=vectorize_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T13:01:19.786056Z",
     "start_time": "2023-07-22T13:01:16.307986Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0050,  0.0219, -0.0453,  ..., -0.0281,  0.0181,  0.0277],\n",
      "        [-0.0302,  0.0471, -0.1138,  ..., -0.0422,  0.0133,  0.0714],\n",
      "        [-0.0120,  0.0416, -0.0291,  ..., -0.0155,  0.0098,  0.0400],\n",
      "        ...,\n",
      "        [-0.0146,  0.0382, -0.0310,  ..., -0.0171, -0.0011,  0.0206],\n",
      "        [-0.0112,  0.0569, -0.0353,  ..., -0.0317,  0.0001,  0.0343],\n",
      "        [-0.0169,  0.0348, -0.0211,  ..., -0.0133,  0.0104,  0.0102]]) tensor([ 6,  2, -1,  ..., -1,  6,  3])\n"
     ]
    }
   ],
   "source": [
    "for X, Y in train_loader:\n",
    "    print(X, Y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T13:13:36.527556Z",
     "start_time": "2023-07-22T13:13:36.521023Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "target_classes = 8\n",
    "\n",
    "class EmbeddingClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EmbeddingClassifier, self).__init__()\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Linear(embed_len, 256),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(256,target_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, X_batch):\n",
    "        x = self.seq(X_batch)\n",
    "        return torch.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T13:13:36.545144Z",
     "start_time": "2023-07-22T13:13:36.532082Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "import gc\n",
    "\n",
    "def CalcValLossAndAccuracy(model, loss_fn, val_loader):\n",
    "    with torch.no_grad():\n",
    "        Y_shuffled, Y_preds, losses = [],[],[]\n",
    "        for X, Y in val_loader:\n",
    "            preds = model(X)\n",
    "            loss = loss_fn(preds, Y)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            Y_shuffled.append(Y)\n",
    "            Y_preds.append(preds.argmax(dim=-1))\n",
    "\n",
    "        Y_shuffled = torch.cat(Y_shuffled)\n",
    "        Y_preds = torch.cat(Y_preds)\n",
    "\n",
    "        print(\"Valid Loss : {:.3f}\".format(torch.tensor(losses).mean()))\n",
    "        print(\"Valid Acc  : {:.3f}\".format(accuracy_score(Y_shuffled.detach().numpy(), Y_preds.detach().numpy())))\n",
    "\n",
    "def TrainModel(model, loss_fn, optimizer, train_loader, val_loader, epochs=10):\n",
    "    for i in range(1, epochs+1):\n",
    "        losses = []\n",
    "        for X, Y in tqdm(train_loader):\n",
    "            Y_preds = model(X)\n",
    "\n",
    "            loss = loss_fn(Y_preds, Y)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "#         if i%5==0:\n",
    "        print(\"Train Loss : {:.3f}\".format(torch.tensor(losses).mean()))\n",
    "        CalcValLossAndAccuracy(model, loss_fn, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T13:19:13.249434Z",
     "start_time": "2023-07-22T13:13:36.553185Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [01:45<00:00,  4.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 2.046\n",
      "Valid Loss : 2.024\n",
      "Valid Acc  : 0.234\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "epochs = 1\n",
    "learning_rate = 1e-3\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "embed_classifier = EmbeddingClassifier()\n",
    "optimizer = Adam(embed_classifier.parameters(), lr=learning_rate)\n",
    "\n",
    "TrainModel(embed_classifier, loss_fn, optimizer, train_loader, test_loader, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T13:24:42.624007Z",
     "start_time": "2023-07-22T13:21:09.441465Z"
    }
   },
   "outputs": [],
   "source": [
    "def MakePredictions(model, loader):\n",
    "    Y_shuffled, Y_preds = [], []\n",
    "    for X, Y in loader:\n",
    "        preds = model(X)\n",
    "        Y_preds.append(preds)\n",
    "        Y_shuffled.append(Y)\n",
    "    gc.collect()\n",
    "    Y_preds, Y_shuffled = torch.cat(Y_preds), torch.cat(Y_shuffled)\n",
    "\n",
    "    return Y_shuffled.detach().numpy(), F.softmax(Y_preds, dim=-1).argmax(dim=-1).detach().numpy()\n",
    "\n",
    "Y_actual, Y_preds = MakePredictions(embed_classifier, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T13:24:59.469712Z",
     "start_time": "2023-07-22T13:24:59.369713Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "print(\"Test Accuracy : {}\".format(accuracy_score(Y_actual, Y_preds)))\n",
    "print(\"\\nClassification Report : \")\n",
    "print(classification_report(Y_actual, Y_preds))\n",
    "print(\"\\nConfusion Matrix : \")\n",
    "print(confusion_matrix(Y_actual, Y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T14:24:38.169529Z",
     "start_time": "2023-07-23T14:24:38.164527Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pickle\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T14:24:38.370463Z",
     "start_time": "2023-07-23T14:24:38.357010Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score\n",
    "def modelEvaluation(predictions):\n",
    "    '''\n",
    "    Print model evaluation to predicted result \n",
    "    '''\n",
    "    print (\"\\nAccuracy on validation set: {:.4f}\".format(accuracy_score(y_test, predictions)))\n",
    "    print(\"\\nClassification report : \\n\", metrics.classification_report(y_test, predictions))\n",
    "    print(\"\\nConfusion Matrix : \\n\", metrics.confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T14:24:39.615919Z",
     "start_time": "2023-07-23T14:24:38.723029Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test_data.csv')\n",
    "df_train = pd.read_csv('train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T14:25:08.116568Z",
     "start_time": "2023-07-23T14:24:39.619782Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, review in enumerate(df_train['text']):\n",
    "    review = re.sub(r'\\W', ' ', review)\n",
    "    review = review.lower()\n",
    "    review = re.sub(r'^br$', ' ', review)\n",
    "    review = re.sub(r'\\s+br\\s+',' ',review)\n",
    "    review = re.sub(r'\\s+[a-z]\\s+', ' ',review)\n",
    "    review = re.sub(r'^b\\s+', '', review)\n",
    "    review = re.sub(r'\\s+', ' ', review)\n",
    "    df_train.loc[0, 'text'] = review\n",
    "\n",
    "for i, review in enumerate(df_test['text']):\n",
    "    review = re.sub(r'\\W', ' ', review)\n",
    "    review = review.lower()\n",
    "    review = re.sub(r'^br$', ' ', review)\n",
    "    review = re.sub(r'\\s+br\\s+',' ',review)\n",
    "    review = re.sub(r'\\s+[a-z]\\s+', ' ',review)\n",
    "    review = re.sub(r'^b\\s+', '', review)\n",
    "    review = re.sub(r'\\s+', ' ', review)\n",
    "    df_test.loc[0, 'text'] = review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T14:25:12.377258Z",
     "start_time": "2023-07-23T14:25:12.334228Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df_train['text']\n",
    "y_train = df_train['rating']\n",
    "\n",
    "X_test = df_test['text']\n",
    "y_test = df_test['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T14:25:18.541066Z",
     "start_time": "2023-07-23T14:25:12.629807Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features : 27272 \n",
      "\n",
      "Show some feature names : \n",
      " ['00' 'alternatively' 'baked' 'bothersome' 'centers' 'complicit' 'cuties'\n",
      " 'disgraced' 'elsewhere' 'fat' 'gainey' 'hamburger' 'ideally' 'ive' 'leer'\n",
      " 'martians' 'mower' 'opponents' 'picaresque' 'prude' 'repairs' 'saruman'\n",
      " 'silverman' 'stands' 'talk' 'trenches' 'verify' 'wreak']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "tfidf = TfidfVectorizer(min_df=5) #minimum document frequency of 5\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T14:35:53.545498Z",
     "start_time": "2023-07-23T14:35:01.958130Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on validation set: 0.5653\n",
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.68      0.71     10122\n",
      "           2       0.45      0.50      0.47      4586\n",
      "           3       0.47      0.48      0.48      4961\n",
      "           4       0.50      0.55      0.53      5331\n",
      "           7       0.49      0.55      0.52      4803\n",
      "           8       0.51      0.47      0.49      5859\n",
      "           9       0.45      0.49      0.47      4608\n",
      "          10       0.68      0.63      0.65      9731\n",
      "\n",
      "    accuracy                           0.57     50001\n",
      "   macro avg       0.54      0.54      0.54     50001\n",
      "weighted avg       0.57      0.57      0.57     50001\n",
      "\n",
      "\n",
      "Confusion Matrix : \n",
      " [[6905 1236  795  592  135  120  100  239]\n",
      " [ 965 2275  533  491  103   53   57  109]\n",
      " [ 602  619 2369  805  232  115   73  146]\n",
      " [ 403  467  676 2951  392  193  122  127]\n",
      " [  66  110  189  398 2658  580  379  423]\n",
      " [  93  101  169  267  895 2745  707  882]\n",
      " [  70   62   89  145  409  571 2263  999]\n",
      " [ 219  159  168  195  602  969 1319 6100]]\n",
      "\n",
      "Accuracy on validation set: 0.4786\n",
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.80      0.61     10122\n",
      "           2       0.64      0.22      0.33      4586\n",
      "           3       0.44      0.29      0.35      4961\n",
      "           4       0.49      0.35      0.41      5331\n",
      "           7       0.47      0.35      0.40      4803\n",
      "           8       0.54      0.30      0.38      5859\n",
      "           9       0.54      0.22      0.31      4608\n",
      "          10       0.44      0.73      0.55      9731\n",
      "\n",
      "    accuracy                           0.48     50001\n",
      "   macro avg       0.51      0.41      0.42     50001\n",
      "weighted avg       0.50      0.48      0.45     50001\n",
      "\n",
      "\n",
      "Confusion Matrix : \n",
      " [[8082  214  739  491   79   44   26  447]\n",
      " [2363 1031  361  347   64   30   13  377]\n",
      " [2068  134 1458  472  138   69   25  597]\n",
      " [1800  109  321 1854  256  119   43  829]\n",
      " [ 545   39  129  249 1672  316   99 1754]\n",
      " [ 536   28  123  166  488 1735  170 2613]\n",
      " [ 338   20   61   82  317  313 1000 2477]\n",
      " [ 723   29  108  144  548  599  484 7096]]\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(max_iter=1000, class_weight = 'balanced')\n",
    "\n",
    "nb = BernoulliNB()\n",
    "\n",
    "\n",
    "models = [logreg, nb]\n",
    "\n",
    "i = 0\n",
    "for model in models:\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "    predictions = model.predict(tfidf.transform(X_test))\n",
    "    modelEvaluation(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T14:36:10.310363Z",
     "start_time": "2023-07-23T14:36:10.262897Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "With smallest coefficients :\n",
      "['great' 'but' 'best' 'excellent' 'also' 'good' 'love' 'very' 'pretty'\n",
      " 'and' 'well' 'enjoyed' 'fun' 'little' 'perfect' 'story' 'quite'\n",
      " 'definitely' 'today' 'it' 'nice' 'his' 'overall' 'played' 'although'\n",
      " 'young' 'much' 'always' 'recommend' 'amazing' 'though' 'favorite'\n",
      " 'wonderful' 'fantastic']\n",
      "\n",
      "With largest coefficients : \n",
      "['worst' 'awful' 'bad' 'terrible' 'waste' 'avoid' 'money' 'even' 'ever'\n",
      " 'horrible' 'this' 'no' 'boring' 'crap' 'stupid' 'garbage' 'nothing'\n",
      " 'worse' 'minutes' 'ridiculous' 'acting' 'they' 'poor' 'pathetic' 'badly'\n",
      " 'any' 'pointless' 'rubbish' 'would' 'trash' 'piece' 'should' 'dreadful']\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.array(tfidf.get_feature_names_out())\n",
    "sorted_coef_index = logreg.coef_[0].argsort()\n",
    "print('\\nWith smallest coefficients :\\n{}\\n'.format(feature_names[sorted_coef_index[:34]]))\n",
    "print('With largest coefficients : \\n{}'.format(feature_names[sorted_coef_index[:-34:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T14:36:22.576809Z",
     "start_time": "2023-07-23T14:36:22.540169Z"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(tfidf,open('tfidf.pkl','wb'))\n",
    "pickle.dump(logreg,open('logisticRegression.pkl','wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
